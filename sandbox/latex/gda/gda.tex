\documentclass{article}
\usepackage{amsmath}

\begin{document}

The log-likelihood can be expressed as follows:

\[
\ell(\theta) = \log p(D | \theta) = \sum_{n=1}^N \log \left( Cat(y_n | \pi) \right) + \sum_{n=1}^N \log \left( N(x_n | \mu_c, \sigma_c) I(y_n = c) \right).
\]

\[
\ell(\theta) = \sum_{n=1}^N \log(\pi_{y_n}) + \sum_{n: y_n = c} \log \left( N(x_n | \mu_c, \sigma_c) \right).
\]


% \[\sum_{n=1}^N \log \left( Cat(y_n | \pi) \right) = \sum_{n=1}^N \log(\pi_{y_n}). \]

% \[N(x_n | \mu_c, \sigma_c) = \frac{1}{\sqrt{2 \pi \sigma_c^2}} \exp\left(-\frac{(x_n - \mu_c)^2}{2 \sigma_c^2}\right). \]


% \[\log N(x_n | \mu_c, \sigma_c) = -\frac{1}{2} \log(2 \pi) - \log(\sigma_c) - \frac{(x_n - \mu_c)^2}{2 \sigma_c^2}. \]

% Thus, the log-likelihood for the normal distribution part becomes:

% \[\sum_{n: y_n = c} \log N(x_n | \mu_c, \sigma_c) = -\frac{N_c}{2} \log(2\pi) - N_c \log(\sigma_c) - \frac{1}{2\sigma_c^2} \sum_{n: y_n = c} (x_n - \mu_c)^2. \]


\[
\ell(\theta) = \sum_{n=1}^N \log(\pi_{y_n}) - \frac{N_c}{2} \log(2\pi) - N_c \log(\sigma_c) - \frac{1}{2\sigma_c^2} \sum_{n: y_n = c} (x_n - \mu_c)^2.
\]

\end{document}

